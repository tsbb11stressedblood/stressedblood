\chapter{Method}\label{cha:intro}

\section{Data sets}
The data provided from the AVIAN Behavioural Genomics and Physiology group consists of around 100 blood smear images. Only around 10-20 of these available images have been used, owing to the fact that labeling these is a very time consuming task. 

\section{Detection and segmentation}

\subsection{Image preprocessing}
The CNN network takes input as four-dimensional arrays of the size nx64x64x3, where the three last dimensions are the width, height and number of channels of the image, and the first denoting how many images there are. For example, an input of 100x64x64x3 means that there are 100 RGB images with the width and height of 64 pixels each. This means that the selected ROIs must be divided into 64 by 64 pixel RGB images in order to be classified by the CNN network. In order to give the best results however, these ROIs should be divided into overlapping squares, with a stride of 8 pixels in both the x and y directions, a value that was empirically arrived at. 

\subsection{Heatmap}
The output from the CNN network for every image is a list of three values, denoting the probability of the image being either a heterophil, a lymphocyte or something other, e.g. a red blood cell or artefacts. Thus, the sum of these values is always equal to one. A heatmap is then generated, with green signifying heterophils, and red lymphocytes. The CNN classifier can sometimes give weaker results on some parts of a cell, for instance if an image part only contains the inner parts of the cell without the cell wall. This problem is mitigated by dilating and blurring the heatmap before thresholding it. Finally, this post-processed image is then used as input to OpenCV's function findContours in conjunction with boundingRect, which returns the bounding box coordinates for the cells.\\
It is then a trivial task to crop these cells out of the ROI image to show in the Results window. Figure \ref{fig:heatmaps} shows an example of this process.\\
The heatmap for the 

\begin{figure}[H]
  \subfloat[]{%
  \begin{minipage}{\linewidth}
  \includegraphics[width=.47\linewidth]{roi_image}\hfill
  \includegraphics[width=.47\linewidth]{scaled_resized_and_cropped_heatmap} %
  \end{minipage}%
  } \par
  \subfloat[]{%
  \begin{minipage}{\linewidth}
  \includegraphics[width=.3\linewidth]{green_dilated_and_blurred_heatmap}\hfill
  \includegraphics[width=.3\linewidth]{green_thresholded} \hfill
  \includegraphics[width=.3\linewidth]{contours_for_green}%
  \end{minipage}%
  } \par
  \subfloat[]{%
  \begin{minipage}{\linewidth}
  \includegraphics[width=.3\linewidth]{red_dilated_and_blurred_heatmap}\hfill
  \includegraphics[width=.3\linewidth]{red_thresholded} \hfill
  \includegraphics[width=.3\linewidth]{contours_for_red}%
  \end{minipage}%
  }
  \caption{Figure (a) depicts the original ROI image to the left and its heatmap to the right. Figure (b) depicts the blurred and dilated heatmap for the heterophil cell to the left with thresholded counterpart in the middle, and its contour to the right. Figure (c) depicts the same as (b) but for the lymphocyte. }
\label{fig:heatmaps}
\end{figure}

\section{Data gathering}\label{sec:research:history}
The GNU Image Manipulation Program, or GIMP, is used for extracting images of cells for training the neural network. However, the blood smear images are too large to handle, so before extracting these cell images the blood smear image is split into smaller files with a size of 2048 by 2048 pixels. Some of these images are chosen in accordance with the method described in 1.5.3. These smaller images are then opened in The GIMP, where a new layer is added, and squares of different colors representing the different cell types are drawn on top of the cells. When all white blood cells have been covered with a square of the corresponding color, the layer with the squares is saved as a PNG image. A simple python script then reads both of these images, and uses the coordinates of the squares to cut out the cells from the cell image and saves them as a sequence of PNG images with the naming convention celltype\_number.png, e.g. lymphocyte\_1.png, lymphocyte\_2.png, ..., lymphocyte\_n.png.

\section{Implementation}\label{sec:research:history}

\subsection{Neural network structure}\label{sec:research:history}
The neural network consists of a number of layers in the following order:

\begin{enumerate}  
\item An RGB input layer of 64 by 64 pixels
\item A convolutional layer with 32 filters, 5 by 5 pixels in size.
\item A max pooling layer of stride 2 in both x and y.
\item A convolutional layer with 32 filters, 5 by 5 pixels in size.
\item A max pooling layer of stride 2 in both x and y.
\item A convolutional layer with 32 filters, 5 by 5 pixels in size.
\item A max pooling layer of stride 2 in both x and y.
\item A fully connected layer of 256 units, with 50\% dropout.
\item A fully connected layer of 3 units, with 50\% dropout.
\end{enumerate}

All layers except the last use the Rectified Linear Unit (ReLU) as an activation function, which has been shown to perform better than for example sigmoid activation functions CITATION HERE.
The ReLU is defined as $\phi(x) =  max(0,x)$.
The last layer uses a softmax activation function, which gives a differentiable approximation of the non-differentiable ReLU function. It is defined as
$\phi(x)_j = \frac{e^{x_j}}{\sum_{k=1}^{K}{e^{x_k}}}$

The structure of the neural network is shown in Figure \ref{fig:nnstructure}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../fig/nnstructure.png}
    \caption{Neural network structure.}
    \label{fig:nnstructure}
\end{figure}


\subsection{Framework}\label{sec:research:history}
The implementation is done in Theano and Lasagne for the Convolutional Neural Network in Python, with additional libraries simplifying and greatly reducing computation time, most notably NumPy for efficient array computations. 

\subsection{Preprocessing}\label{sec:research:history}

\section{Graphical User Interface}
Since this thesis aims to create a semi-automatic method for obtaining an HL ratio, an easy to use GUI must be included. This section details the design and implementation of this interface.

\subsection{Design}
The GUI consists of two main windows, where the first consists of an image viewer that supports zooming in and out of the blood smear image, and the drawing of ROIs. When the user is satisfied with the selected ROIs and clicks on the button labeled "Run", the main algorithm that finds the heterophils and lymphocytes is run, which may take several minutes up to hours, depending on the size of the selected ROIs. When the algorithm is done, the second main window pops up, which shows a grid of nine cells, with left and right buttons to show the next and previous cells found. In this window, it is also possible to show only one type of cell, or choose between the ROIs created. In the upper left corner, the HL ratio for the currently chosen ROI(s) is shown. By right-clicking on the cells in the grid, it is possible to remove or move cells to another category, for example if a lymphocyte is wrongly classified as a heterophil. This feature can be seen in Figure \ref{fig:gui_remove}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../fig/select_rois2.png}
    \caption{Simple example showing how the main window of the GUI works, with a minimal ROI selected.}
    \label{fig:gui_main}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../fig/results.png}
    \caption{Results from the previous ROI, where the first cell is a probable wrongly classified red blood cell.}
    \label{fig:gui_results}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics{../fig/moveto.png}
    \caption{Right-click menu showing the different options for removing or moving cells to another category.}
    \label{fig:gui_remove}
\end{figure}


\subsection{Implementation}
The interface was implemented in Qt Creator, which is a cross-platform integrated development environment (IDE) that includes an integrated GUI layout and forms designer. This greatly reduced the implementation time since GUI design can otherwise be a tedious and time consuming activity. 

\section{Evaluation}\label{sec:research:history}
